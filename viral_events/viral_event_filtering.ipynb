{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for selecting events from the Viraalivahti database. The script selects events that have received an initial score of 5/5 among all hashtag and keyword events. The script currently does not work for other kinds of events but can be modified to do so. The events are then matched with the original Futusome database query corresponding to the event.\n",
    "\n",
    "The script takes as input two files. The file called \"viral_scores_export.csv\" contains one line for each scoring of an event. As each event is scored a total of nine times, this theoretically means that there should be nine lines for each event, but in reality there are some missing lines. The file \"viral_events.csv\" contains information about the events itself, including the event type and its original query.\n",
    "\n",
    "The output is a file called \"keywords_hashtag_initials.csv\", which contains one line for each selected event, listing the score it has been given by the different scorers, its total score, its initial score (which should always be five) and the original query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup script and read databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some scorings are done several times, for example growth of post volume is in most cases scored four times per event. The following part takes this into account. The scores should be in a chronological order in the database, so the script simply loops through them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_scores(path):\n",
    "\n",
    "    score_names = \"\"\"Total number of different authors\n",
    "Total volume\n",
    "Author Growth\n",
    "Identifier\n",
    "Initial burst\n",
    "associated events\n",
    "RT Growth\n",
    "Growth\"\"\"\n",
    "\n",
    "    score_names = score_names.split('\\n')\n",
    "    \n",
    "    events = collections.defaultdict(dict)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "    \n",
    "        reader = csv.DictReader(f, delimiter = ',')\n",
    "    \n",
    "        for row in reader:\n",
    "            event_id = row['event_id']\n",
    "            name = row['name']\n",
    "            score = row['score']\n",
    "        \n",
    "            for score_name in score_names:\n",
    "                if name.startswith(score_name):\n",
    "                \n",
    "                    if score_name.startswith('Growth'):\n",
    "                        period = len([x for x in events[event_id].keys() if x.startswith('Growth')])\n",
    "                        score_name += ' ' + str(period)\n",
    "                    elif score_name.startswith('Author Growth'):\n",
    "                        period = len([x for x in events[event_id].keys() if x.startswith('Author Growth')])\n",
    "                        score_name += ' ' + str(period)\n",
    "                    elif score_name.startswith('Total volume'):\n",
    "                        period = len([x for x in events[event_id].keys() if x.startswith('Total volume')])\n",
    "                        score_name += ' ' + str(period)\n",
    "                    elif score_name.startswith('Total number of different authors'):\n",
    "                        period = len([x for x in events[event_id].keys() if x.startswith('Total number of different authors')])\n",
    "                        score_name += ' ' + str(period)\n",
    "                    \n",
    "                    events[event_id][score_name] = int(score)\n",
    "        \n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read event ids from another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_event_ids(path, events):\n",
    "\n",
    "    with open('data/csv/viral_events.csv', 'r') as f:\n",
    "    \n",
    "        reader = csv.DictReader(f, delimiter = ',')\n",
    "    \n",
    "        for row in reader:\n",
    "            event_type = row['type'].replace('::', ' ').split()[1]\n",
    "            event_id = row['id']\n",
    "            query = row['query']\n",
    "            events[event_id]['type'] = event_type\n",
    "            events[event_id]['query'] = query\n",
    "            \n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute initial scores. What scorers to use for initial scoring depends on the event type. Here the appropriate scorers for each event type are listed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_scores(events):\n",
    "\n",
    "    initial_scores = {}\n",
    "\n",
    "    initial_scores['FacebookHashtagEvent'] = ['Identifier', 'Initial burst', 'Total number of different authors 0',\n",
    "                                     'Growth 0', 'Author Growth 0']\n",
    "    initial_scores['TextKeywordEvent'] = ['Initial burst', 'Total number of different authors 0', 'Growth 0', \n",
    "                                  'Author Growth 0', 'Author Growth 1']\n",
    "    initial_scores['InstagramHashtagEvent'] = ['Identifier', 'Initial burst', 'Total number of different authors 0',\n",
    "                                      'Growth 0', 'Author Growth 0']\n",
    "    initial_scores['FacebookTextKeywordEvent'] = ['Initial burst', 'Total number of different authors 0', 'Growth 0',\n",
    "                                         'Author Growth 0', 'Author Growth 1']\n",
    "    initial_scores['TwitterHashtagEvent'] = ['Identifier', 'Initial burst', 'Growth 0', 'RT Growth', 'Author Growth 0']\n",
    "    \n",
    "    ## List which scorers to use for which event types\n",
    "    ## To make this work for more event types, add the appropriate scorers here\n",
    "\n",
    "    for event_id, scores in events.iteritems():\n",
    "\n",
    "        initial = None\n",
    "        event_type = scores['type']\n",
    "\n",
    "        if event_type in initial_scores.keys():\n",
    "            initial = 0\n",
    "            for score in initial_scores[event_type]:\n",
    "                initial += scores.get(score, 0)\n",
    "\n",
    "        scores['initial_score'] = initial\n",
    "        _scores = scores.copy()\n",
    "        _scores.pop('initial_score')\n",
    "        _scores.pop('query')\n",
    "        _scores.pop('type')\n",
    "\n",
    "        total = sum([int(score) for name, score in _scores.iteritems()])\n",
    "        events[event_id]['total'] = total\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for writing the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(events, out_path):\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "\n",
    "        writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for event_id, scores in events.iteritems():\n",
    "\n",
    "            e = {}\n",
    "            e['event_id'] = event_id\n",
    "\n",
    "            for score_name, score_value in scores.iteritems():\n",
    "                e[score_name] = score_value\n",
    "\n",
    "            writer.writerow(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function especially may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = read_scores('data/csv/viral_scores_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = read_event_ids('data/csv/viral_events.csv', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = get_initial_scores(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the number of events of the selected type that have an initial score of 5 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_events = dict((event_id, scores) for event_id, scores in e.iteritems() if scores.get('initial_score', 0) == 5)\n",
    "print str(len(initial_events)) + ' hashtag and keyword events with initial score 5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_file(events, 'data/csv/keywords_hashtags_initial.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
